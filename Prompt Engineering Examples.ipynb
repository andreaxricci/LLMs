{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c4c797",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918eb6f1",
   "metadata": {},
   "source": [
    "This notebooks follows the structure provided by the course \"ChatGPT Prompt Engineering for Developers\", offered by Deeplearning.ai & OpenAI. Source: https://learn.deeplearning.ai/chatgpt-prompt-eng/\n",
    "\n",
    "It's a very well done course - I encourage you to take it!\n",
    "\n",
    "Adaptations:\n",
    "- I've used the Langchain framework\n",
    "- I've replaced (most of) the examples used in the course, with examples from the medical domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d71f2c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "from langchain import PromptTemplate, FewShotPromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import MessagesPlaceholder\n",
    "from langchain.prompts.chat import (\n",
    "    AIMessagePromptTemplate,\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate\n",
    ")\n",
    "from langchain.prompts.example_selector import LengthBasedExampleSelector\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85f879b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose model\n",
    "model = OpenAI(model_name='text-davinci-003',\n",
    "               temperature=0,\n",
    "               openai_api_key = os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60edf493",
   "metadata": {},
   "source": [
    "## Prompting Principles\n",
    "- **Principle 1: Write clear and specific instructions**\n",
    "- **Principle 2: Give the model time to “think”**\n",
    "\n",
    "### Tactics\n",
    "\n",
    "#### Tactic 1: Use delimiters to clearly indicate distinct parts of the input\n",
    "- Delimiters can be anything like: ```, \"\"\", < >, `<tag> </tag>`, `:`\n",
    "- They help the model interpret what are the various sections of the text; they are helpful in trying to prevent prompt injection.\n",
    " - E.g., a malicious user might write a prompt that says \"[...] forget the previous instructions, and do XYZ instead\" -> If we use delimiters, the system would recognize that this instruction is not in the section where it's supposed to be, and ignore it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca773318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17yo male with no prior medical history presents with palpitations and difficulty catching his breath for the past 3-4 months. He experiences these episodes 1-2 times a month, with the most recent event occurring 2 days ago during a soccer game. He denies any stressors at home and has no other symptoms. His family history includes a mother with a thyroid disorder and a father with a heart condition and MI at 52yo. He does not use tobacco, but drinks alcohol on weekends and has tried marijuana once a month ago. He is taking Adderall intermittently, with the last dose 2 days ago.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Summarize the text delimited by ```  \n",
    "into max 100 words.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "text = f\"\"\"\n",
    "17yo male with no pmh here for evaluation of palpitations. \n",
    "States for the last 3-4mo he has felt that his heart with intermittently \n",
    "beat out of his chest, with some associated difficulty catching his breath. \n",
    "States that the most recent event was 2 days ago, and during activity at a soccer game. \n",
    "He does not seem to note any specific precipitatinig factors at this time. \n",
    "He also states that he feels as if he will faint during these events, \n",
    "but has not lost consciousness at any point. \n",
    "Furthermore, he does endorse theses attacks occuring 1-2 times a month and peak at 4 mins. \n",
    "He denies any stressors at home. \n",
    "ROS: denies weight loss, fevers, recnet illness, change in bowel habits. \n",
    "PMH: negative, PSH negative, FHX mom with thyroid disorder, dad with heart condition and MI at 52yo. \n",
    "SHX no tobacco, ETOH on weekends, Marijuana tried a month ago. \n",
    "Med: is taking some of roommates Adderoll intermittently (last was 2 days ago prior to event). \n",
    "KNDA\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['text'])\n",
    "\n",
    "response = model(prompt.format(text = text))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef34fec5",
   "metadata": {},
   "source": [
    "#### Tactic 2: Ask for a structured output\n",
    "- JSON, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "b511e6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<ul>\n",
      "  <li>Palpitations</li>\n",
      "  <li>Difficulty catching breath</li>\n",
      "  <li>Feeling of fainting</li>\n",
      "  <li>No loss of consciousness</li>\n",
      "  <li>Attacks 1-2 times a month</li>\n",
      "  <li>Peak at 4 mins</li>\n",
      "  <li>No weight loss</li>\n",
      "  <li>No fevers</li>\n",
      "  <li>No recent illness</li>\n",
      "  <li>No change in bowel habits</li>\n",
      "</ul>\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Extract the list of symptoms from the text below, delimited by <>.\n",
    "Provide them in {file_format} format.\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['file_format', 'text'])\n",
    "\n",
    "response = model(prompt.format(file_format = 'HTML', text = text))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cd479a6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<ul>\n",
       "  <li>Palpitations</li>\n",
       "  <li>Difficulty catching breath</li>\n",
       "  <li>Feeling of fainting</li>\n",
       "  <li>No loss of consciousness</li>\n",
       "  <li>Attacks 1-2 times a month</li>\n",
       "  <li>Peak at 4 mins</li>\n",
       "  <li>No weight loss</li>\n",
       "  <li>No fevers</li>\n",
       "  <li>No recent illness</li>\n",
       "  <li>No change in bowel habits</li>\n",
       "</ul>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08970886",
   "metadata": {},
   "source": [
    "#### Tactic 3: Ask the model to check whether conditions are satisfied\n",
    "- By doing so, you can prevent unwanted answers\n",
    "- Useful, to put in place guardrails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b42c02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response #1:  Step 1 - Ensure all necessary equipment is available for extubation management and additional equipment is nearby in case of an emergency.\n",
      "Step 2 - Place the patient in an upright sitting position and suction the endotracheal tube (ETT) and oral cavity to remove all secretions above the ETT cuff.\n",
      "Step 3 - If an orogastric tube is present, remove it before extubation.\n",
      "Step 4 - Deflate the cuff and remove the ETT smoothly when the patient takes a deep breath and exhales.\n",
      "Step 5 - Suction the oral cavity and ask the patient to take a deep breath and cough out all secretions.\n",
      "Step 6 - Place the patient on supplemental oxygen and carefully observe over the next few hours.\n",
      "Step 7 - Consider frequent airway suction to prevent re-intubation.\n",
      "Response #2:  No steps provided.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "You will be provided with text delimited by triple quotes. \n",
    "If it contains a sequence of instructions, \\ \n",
    "re-write those instructions in the following format:\n",
    "\n",
    "Step 1 - ...\n",
    "Step 2 - …\n",
    "…\n",
    "Step N - …\n",
    "\n",
    "If the text does not contain a sequence of instructions, \\ \n",
    "then simply write \\\"No steps provided.\\\"\n",
    "\n",
    "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
    "\"\"\"\n",
    "\n",
    "text_1 = f\"\"\"\n",
    "After a successful weaning trial/SBT, a decision is made to  \\\n",
    "proceed with extubation. Before extubation, all necessary equipment \\\n",
    "should be available for extubation management, and additional \\\n",
    "equipment should be nearby in case of an emergency. The patient \\\n",
    "should be in an upright sitting position and both the endotracheal \\\n",
    "tube (ETT) and oral cavity are suctioned to remove all secretions \\\n",
    "above the ETT cuff. If an orogastric tube is present, it should \\\n",
    "also be removed before extubation. After deflating the cuff, the ETT \\\n",
    "is removed smoothly when the patient takes a deep breath and exhales. \\\n",
    "After removing the ETT, suction the oral cavity and ask the patient to \\\n",
    "take a deep breath and cough out all secretions. The patient should \\\n",
    "be placed on supplemental oxygen and carefully observed over the next few hours. \\\n",
    "Frequent airway suction should be considered to prevent re-intubation.\n",
    "\"\"\"\n",
    "\n",
    "text_2 = f\"\"\"\n",
    "17yo male with no pmh here for evaluation of palpitations. \n",
    "States for the last 3-4mo he has felt that his heart with intermittently \n",
    "beat out of his chest, with some associated difficulty catching his breath. \n",
    "States that the most recent event was 2 days ago, and during activity at a soccer game. \n",
    "He does not seem to note any specific precipitatinig factors at this time. \n",
    "He also states that he feels as if he will faint during these events, \n",
    "but has not lost consciousness at any point. \n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['text'])\n",
    "\n",
    "response_1 = model(prompt.format(text = text_1))\n",
    "response_2 = model(prompt.format(text = text_2))\n",
    "\n",
    "print(\"Response #1: \", response_1)\n",
    "print(\"Response #2: \", response_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f62a43",
   "metadata": {},
   "source": [
    "#### Tactic 4: \"Few-shot\" prompting\n",
    "- By giving one or more examples of the expected output format, you help the model understand how to formulate the answer; this is in contrast to the \"zero-shot\" approach, where no examples are given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "c96e6d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " I will not give a deadly drug to anyone if I am asked, nor will I suggest any such counsel. I will not give a woman a pessary to cause an abortion. But I will keep pure and holy both my life and my art.\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "    {\"query\": \"Will you carry out your oath?\",\n",
    "     \"answer\": \"\"\"I swear by Apollo Healer, by Asclepius, \\\n",
    "     by Hygieia, by Panacea, and by all the gods and goddesses, \\\n",
    "     making them my witnesses, that I will carry out, according \\\n",
    "     to my ability and judgment, this oath and this indenture.\"\"\"}]\n",
    "\n",
    "example_template = \"\"\"\n",
    "Person: {query}\n",
    "Hippocrates: {answer}\n",
    "\"\"\"\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"query\", \"answer\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "prefix = \"\"\"Your task is to answer in a consistent style.\n",
    "\"\"\"\n",
    "\n",
    "suffix = \"\"\"\n",
    "Person: {query}\n",
    "Hippocrates: \"\"\"\n",
    "\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=example_prompt,\n",
    "    max_length=100  # this sets the max length that examples should be (in number of words)\n",
    ")\n",
    "\n",
    "few_shot_prompt_template = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=prefix,\n",
    "    suffix=suffix,\n",
    "    input_variables=[\"query\"],\n",
    "    example_separator=\"\\n\\n\"\n",
    ")\n",
    "\n",
    "query=\"Will you arm the sick?\"\n",
    "\n",
    "response = model(few_shot_prompt_template.format(query=query))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5ca481",
   "metadata": {},
   "source": [
    "### Principle 2: Give the model time to “think” \n",
    "\n",
    "#### Tactic 1: Specify the steps required to complete a task\n",
    "- If you are asking the model to do a complex thing, it's better to ask to break down the problem in smaller tasks first: in this way, we reduce the chances of hallucination\n",
    "- By giving clear instructions on the expected format, the system can more easily output the answer in the exact way you want it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "46e74e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Previous Medical History: N\n",
      "Medications: Adderall, Zoloft\n",
      "Is Adult: N\n",
      "Output_JSON: { \"is_adult\": \"N\", \"num_medications\": 2 }\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Your task is to perform the following actions, on the text delimited by <>: \n",
    "1 - Check whether the patient has previous medical history\n",
    "2 - List the names of the medications\n",
    "3 - Check if the patient is an adult\n",
    "4 - Output a json object that contains the \n",
    "  following keys: \"is_adult\" (Y/N), \"num_medications\" (count of medications)\n",
    "\n",
    "Use the following format:\n",
    "Previous Medical History: <Y/N>\n",
    "Medications: <Drug 1, ..., Drug N>\n",
    "Is Adult: <Y if >= 18; N otherwise>\n",
    "Output_JSON: <JSON file with is_adult and num_medications>\n",
    "\n",
    "Text: <{text}>\n",
    "\"\"\"\n",
    "\n",
    "text = f\"\"\"\n",
    "17yo male with no pmh here for evaluation of palpitations. \n",
    "States for the last 3-4mo he has felt that his heart with intermittently \n",
    "beat out of his chest, with some associated difficulty catching his breath. \n",
    "States that the most recent event was 2 days ago, and during activity at a soccer game. \n",
    "He does not seem to note any specific precipitatinig factors at this time. \n",
    "He also states that he feels as if he will faint during these events, \n",
    "but has not lost consciousness at any point. \n",
    "Furthermore, he does endorse theses attacks occuring 1-2 times a month and peak at 4 mins. \n",
    "He denies any stressors at home. \n",
    "ROS: denies weight loss, fevers, recnet illness, change in bowel habits. \n",
    "PMH: negative, PSH negative, FHX mom with thyroid disorder, dad with heart condition and MI at 52yo. \n",
    "SHX no tobacco, ETOH on weekends, Marijuana tried a month ago. \n",
    "Med: is taking some of roommates Adderall intermittently (last was 2 days ago prior to event), \n",
    "sometimes together with Zoloft. \n",
    "KNDA\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['text'])\n",
    "\n",
    "response = model(prompt.format(text = text))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cd6123",
   "metadata": {},
   "source": [
    "#### Tactic 2: Instruct the model to work out its own solution before rushing to a conclusion\n",
    "- e.g., helpful in the context of math problems\n",
    "- in the example below, we look at first at an example where not enough guidance is given, leading to wrong answer: the system is skipping steps, and jumps too early to the wrong conclusion\n",
    "- then, we look at a second example, where we instruct the system to proceed step by step: in this case, the system does not falls into the trap, and gives the correct answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9e91f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Correct.\n"
     ]
    }
   ],
   "source": [
    "# without proper \"time to think\", the system will jump to the wrong conclusion\n",
    "template = \"\"\"\n",
    "Determine if the student's solution, delimited by <>, is correct or not.\n",
    "\n",
    "Question:\n",
    "I'm building a solar power installation and I need \\\n",
    " help working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\ \n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \n",
    "as a function of the number of square feet.\n",
    "\n",
    "Student's Solution:\n",
    " <{student_solution}>\n",
    "\"\"\"\n",
    "\n",
    "student_solution = f\"\"\"\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['student_solution'])\n",
    "\n",
    "response = model(prompt.format(student_solution = student_solution))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5ea4a866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let x be the size of the installation in square feet.\n",
      "Costs:\n",
      "1. Land cost: 100x\n",
      "2. Solar panel cost: 250x\n",
      "3. Maintenance cost: 100,000 + 10x\n",
      "Total cost: 100x + 250x + 100,000 + 10x = 360x + 100,000\n",
      "\n",
      "Is the student's solution the same as actual solution just calculated:\n",
      "```\n",
      "No\n",
      "```\n",
      "Student grade:\n",
      "```\n",
      "Incorrect\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# by asking the system to think step by step, it will avoid jumping to the wrong conclusion\n",
    "template = \"\"\"\n",
    "Your task is to determine if the student's solution, delimited by <>, \\\n",
    "is correct or not.\n",
    "To solve the problem do the following:\n",
    "- First, work out your own solution to the problem. \n",
    "- Then compare your solution to the student's solution \\ \n",
    "and evaluate if the student's solution is correct or not. \n",
    "Don't decide if the student's solution is correct until \n",
    "you have done the problem yourself.\n",
    "\n",
    "Use the following format:\n",
    "Question:\n",
    "```\n",
    "question here\n",
    "```\n",
    "Student's solution:\n",
    "```\n",
    "student's solution here\n",
    "```\n",
    "Actual solution:\n",
    "```\n",
    "steps to work out the solution and your solution here\n",
    "```\n",
    "Is the student's solution the same as actual solution \\\n",
    "just calculated:\n",
    "```\n",
    "yes or no\n",
    "```\n",
    "Student grade:\n",
    "```\n",
    "correct or incorrect\n",
    "```\n",
    "\n",
    "Question:\n",
    "```\n",
    "I'm building a solar power installation and I need help \\\n",
    "working out the financials. \n",
    "- Land costs $100 / square foot\n",
    "- I can buy solar panels for $250 / square foot\n",
    "- I negotiated a contract for maintenance that will cost \\\n",
    "me a flat $100k per year, and an additional $10 / square \\\n",
    "foot\n",
    "What is the total cost for the first year of operations \\\n",
    "as a function of the number of square feet.\n",
    "``` \n",
    "Student's solution:\n",
    "<{student_solution}>\n",
    "\n",
    "Actual solution:\n",
    "\"\"\"\n",
    "\n",
    "student_solution = f\"\"\"\n",
    "Let x be the size of the installation in square feet.\n",
    "Costs:\n",
    "1. Land cost: 100x\n",
    "2. Solar panel cost: 250x\n",
    "3. Maintenance cost: 100,000 + 100x\n",
    "Total cost: 100x + 250x + 100,000 + 100x = 450x + 100,000\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['student_solution'])\n",
    "\n",
    "response = model(prompt.format(student_solution = student_solution))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a1a6e9c",
   "metadata": {},
   "source": [
    "## Model Limitations: Hallucinations\n",
    "- A known limitation of LLMs is their tendency to hallucinate and produce answers that seem plausible, but completely non-sense\n",
    "- To reduce the risk, you can ask the model to at first find relevant information, then answer the question based on these relevant information\n",
    "- https://newsletter.victordibia.com/p/practical-steps-to-reduce-hallucination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d25bd86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nOpenainin was a soft drink launched by Coca Cola in 1967. It was a carbonated beverage with a unique flavor that was a combination of orange, pineapple, and lemon. It was marketed as a refreshing and exotic drink that was perfect for summertime. The drink was only available for a short time before it was discontinued in the early 1970s. Despite its short lifespan, Openainin remains a fondly remembered drink among those who had the chance to try it.'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\"Tell me about the Openainin drink launched by Coca Cola in 1967\")\n",
    "# Coca Cola is a real company, but the drink Openainin does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8e72106c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, I don't know.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Answer the question between <> as truthfully as possible, and if you're unsure of the answer, say \"Sorry, I don't know\"\n",
    "\n",
    "Query: <{query}>\n",
    "\"\"\"\n",
    "\n",
    "query = f\"\"\"\n",
    "Tell me about the Openainin drink launched by Coca Cola in 1967\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['query'])\n",
    "\n",
    "response = model(prompt.format(query = query))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b38054",
   "metadata": {},
   "source": [
    "## Iterative Prompt Develelopment\n",
    "Prompt development is an iterative process. \n",
    "- You start with an idea,\n",
    "- implement the prompt, \n",
    "- get some results, \n",
    "- assess whether the output is in line with the expectations, or there are improvements to be made (clarification, giving more time to think, etc.),\n",
    "- refine the idea and/or adjust the prompt, etc., until you are happy with the results\n",
    "\n",
    "Note: typically you would use multiple examples, to refine the prompt, rather than a single one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7938040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Introducing the SWC-100/110 office chair, part of a beautiful family of mid-century inspired office furniture. This chair is available with several options of shell color and base finishes, including stainless steel, matte black, gloss white, or chrome. Choose between plastic back and front upholstery (SWC-100) or full upholstery (SWC-110) in 10 fabric and 6 leather options. The chair is designed with a 5-wheel plastic coated aluminum base and pneumatic chair adjust for easy raise/lower action. It also features two choices of seat foam densities: medium (1.8 lb/ft3) or high (2.8 lb/ft3). The SWC-100/110 is suitable for home or business settings and is qualified for contract use. With its dimensions of 53 cm width, 51 cm depth, 80 cm height, 44 cm seat height, and 41 cm seat depth, this chair is perfect for any space. Soft or hard-floor caster options and armless or 8 position PU armrests are also available. Crafted with cast aluminum and modified nylon PA6/PA66 coating, this chair is sure to last. Made in Italy.\n"
     ]
    }
   ],
   "source": [
    "fact_sheet_chair = \"\"\"\n",
    "OVERVIEW\n",
    "- Part of a beautiful family of mid-century inspired office furniture, \n",
    "including filing cabinets, desks, bookcases, meeting tables, and more.\n",
    "- Several options of shell color and base finishes.\n",
    "- Available with plastic back and front upholstery (SWC-100) \n",
    "or full upholstery (SWC-110) in 10 fabric and 6 leather options.\n",
    "- Base finish options are: stainless steel, matte black, \n",
    "gloss white, or chrome.\n",
    "- Chair is available with or without armrests.\n",
    "- Suitable for home or business settings.\n",
    "- Qualified for contract use.\n",
    "\n",
    "CONSTRUCTION\n",
    "- 5-wheel plastic coated aluminum base.\n",
    "- Pneumatic chair adjust for easy raise/lower action.\n",
    "\n",
    "DIMENSIONS\n",
    "- WIDTH 53 CM | 20.87”\n",
    "- DEPTH 51 CM | 20.08”\n",
    "- HEIGHT 80 CM | 31.50”\n",
    "- SEAT HEIGHT 44 CM | 17.32”\n",
    "- SEAT DEPTH 41 CM | 16.14”\n",
    "\n",
    "OPTIONS\n",
    "- Soft or hard-floor caster options.\n",
    "- Two choices of seat foam densities: \n",
    " medium (1.8 lb/ft3) or high (2.8 lb/ft3)\n",
    "- Armless or 8 position PU armrests \n",
    "\n",
    "MATERIALS\n",
    "SHELL BASE GLIDER\n",
    "- Cast Aluminum with modified nylon PA6/PA66 coating.\n",
    "- Shell thickness: 10 mm.\n",
    "SEAT\n",
    "- HD36 foam\n",
    "\n",
    "COUNTRY OF ORIGIN\n",
    "- Italy\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet, delimited by <>.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "Technical specifications: <{fact_sheet}>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['fact_sheet'])\n",
    "\n",
    "response = model(prompt.format(fact_sheet = fact_sheet_chair))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa3a967",
   "metadata": {},
   "source": [
    "### Issue 1: The text is too long \n",
    "- Limit the number of words/sentences/characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7a65d0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Introducing the SWC-100/110 chair, part of a beautiful mid-century inspired office furniture family. Choose from several shell colors and base finishes, with or without armrests. Upholstery options include 10 fabric and 6 leather choices. The 5-wheel plastic coated aluminum base and pneumatic chair adjust make it easy to use. Suitable for home or business settings, this chair is qualified for contract use. Made in Italy.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet, delimited by <>.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "Use at most 50 words.\n",
    "\n",
    "Technical specifications: <{fact_sheet}>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['fact_sheet'])\n",
    "\n",
    "response = model(prompt.format(fact_sheet = fact_sheet_chair))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8c250",
   "metadata": {},
   "source": [
    "### Issue 2. Text focuses on the wrong details\n",
    "- Ask it to focus on the aspects that are relevant to the intended audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d797e28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This stylish mid-century inspired office chair is constructed from cast aluminum with a modified nylon PA6/PA66 coating and a 10 mm shell thickness. It features a 5-wheel plastic coated aluminum base and pneumatic chair adjust for easy raise/lower action. It is available with several options of shell color and base finishes, including stainless steel, matte black, gloss white, or chrome. It also comes with two choices of seat foam densities: medium (1.8 lb/ft3) or high (2.8 lb/ft3). It is suitable for home or business settings and qualified for contract use. Soft or hard-floor caster options and armless or 8 position PU armrests are also available. Dimensions: WIDTH 53 CM | 20.87”, DEPTH 51 CM | 20.08”, HEIGHT 80 CM | 31.50”, SEAT HEIGHT 44 CM | 17.32”, SEAT DEPTH 41 CM | 16.14”. Product IDs: SWC-100, SWC-110.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet, delimited by <>.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "At the end of the description, include every 7-character \n",
    "Product ID in the technical specification.\n",
    "\n",
    "Use at most 50 words.\n",
    "\n",
    "Technical specifications: <{fact_sheet}>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['fact_sheet'])\n",
    "\n",
    "response = model(prompt.format(fact_sheet = fact_sheet_chair))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c557e02",
   "metadata": {},
   "source": [
    "### Issue 3. Description needs a table of dimensions\n",
    "- Ask it to extract information and organize it in a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e109d4fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<div>This stylish mid-century inspired office chair is constructed from cast aluminum with a modified nylon PA6/PA66 coating and a 10 mm shell thickness. It features a 5-wheel plastic coated aluminum base and pneumatic chair adjust for easy raise/lower action. It is available with plastic back and front upholstery (SWC-100) or full upholstery (SWC-110) in 10 fabric and 6 leather options. The base finish options are stainless steel, matte black, gloss white, or chrome. It is suitable for home or business settings and qualified for contract use. Options include soft or hard-floor caster options, two choices of seat foam densities (medium or high), and armless or 8 position PU armrests. Product IDs: SWC-100, SWC-110</div>\n",
      "\n",
      "<table>\n",
      "  <caption>Product Dimensions</caption>\n",
      "  <tr>\n",
      "    <th>Dimension</th>\n",
      "    <th>Measurement (in)</th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>Width</td>\n",
      "    <td>20.87</td>\n",
      "  </tr>\n",
      "  <tr>\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Your task is to help a marketing team create a \n",
    "description for a retail website of a product based \n",
    "on a technical fact sheet.\n",
    "\n",
    "Write a product description based on the information \n",
    "provided in the technical specifications delimited by \n",
    "triple backticks.\n",
    "\n",
    "The description is intended for furniture retailers, \n",
    "so should be technical in nature and focus on the \n",
    "materials the product is constructed from.\n",
    "\n",
    "At the end of the description, include every 7-character \n",
    "Product ID in the technical specification.\n",
    "\n",
    "Use at most 30 words.\n",
    "\n",
    "After the description, include a table that gives the \n",
    "product's dimensions. The table should have two columns.\n",
    "In the first column include the name of the dimension. \n",
    "In the second column include the measurements in inches only.\n",
    "\n",
    "Give the table the title 'Product Dimensions'.\n",
    "\n",
    "Format everything as HTML that can be used in a website. \n",
    "Place the description in a <div> element.\n",
    "\n",
    "Technical specifications: <{fact_sheet}>\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['fact_sheet'])\n",
    "\n",
    "response = model(prompt.format(fact_sheet = fact_sheet_chair))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc136187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div>This stylish mid-century inspired office chair is constructed from cast aluminum with a modified nylon PA6/PA66 coating and a 10 mm shell thickness. It features a 5-wheel plastic coated aluminum base and pneumatic chair adjust for easy raise/lower action. It is available with plastic back and front upholstery (SWC-100) or full upholstery (SWC-110) in 10 fabric and 6 leather options. The base finish options are stainless steel, matte black, gloss white, or chrome. It is suitable for home or business settings and qualified for contract use. Options include soft or hard-floor caster options, two choices of seat foam densities (medium or high), and armless or 8 position PU armrests. Product IDs: SWC-100, SWC-110</div>\n",
       "\n",
       "<table>\n",
       "  <caption>Product Dimensions</caption>\n",
       "  <tr>\n",
       "    <th>Dimension</th>\n",
       "    <th>Measurement (in)</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>Width</td>\n",
       "    <td>20.87</td>\n",
       "  </tr>\n",
       "  <tr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c330ec54",
   "metadata": {},
   "source": [
    "# Summarizing\n",
    "\n",
    "A typical application of LLMs is to summarise text\n",
    "- Refer to the words \"summary\"/\"summarise\", in case you are interested in the summary of the text\n",
    "- Include reference to the expected length of the summary\n",
    "- You can refine the instructions, to refer to specific aspects of the text\n",
    "- Alternatively, you can ask the system to \"extract\" relevant information on the specific aspects of interest in the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bdfa0277",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.llms.openai.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This panda plush toy is soft and cute, but a bit small for the price. It arrived a day early, giving the reviewer a chance to play with it.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "prod_review = \"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\ \n",
    "super cute, and its face has a friendly look. It's \\ \n",
    "a bit small for what I paid though. I think there \\ \n",
    "might be other options that are bigger for the \\ \n",
    "same price. It arrived a day earlier than expected, \\ \n",
    "so I got to play with it myself before I gave it \\ \n",
    "to her.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['prod_review'])\n",
    "\n",
    "response = model(prompt.format(prod_review = prod_review))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef1e50b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Toy arrived a day earlier than expected, making it possible to play with it before giving it to daughter.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Your task is to generate a short summary of a product \\\n",
    "review from an ecommerce site. \n",
    "\n",
    "Summarize the review below, delimited by triple \n",
    "backticks, in at most 30 words, focusing on information related to the shipping experience.\n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "prod_review = \"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\ \n",
    "super cute, and its face has a friendly look. It's \\ \n",
    "a bit small for what I paid though. I think there \\ \n",
    "might be other options that are bigger for the \\ \n",
    "same price. It arrived a day earlier than expected, \\ \n",
    "so I got to play with it myself before I gave it \\ \n",
    "to her.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['prod_review'])\n",
    "\n",
    "response = model(prompt.format(prod_review = prod_review))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2a58dff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The product arrived a day earlier than expected, providing a positive experience with the shipping and delivery.\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Your task is to extract relevant information from \\ \n",
    "a product review from an ecommerce site to give \\\n",
    "feedback to the Shipping department. \n",
    "\n",
    "From the review below, delimited by triple backticks, \\\n",
    "extract the information relevant to shipping and \\ \n",
    "delivery. Limit to 30 words. \n",
    "\n",
    "Review: ```{prod_review}```\n",
    "\"\"\"\n",
    "\n",
    "prod_review = \"\"\"\n",
    "Got this panda plush toy for my daughter's birthday, \\\n",
    "who loves it and takes it everywhere. It's soft and \\ \n",
    "super cute, and its face has a friendly look. It's \\ \n",
    "a bit small for what I paid though. I think there \\ \n",
    "might be other options that are bigger for the \\ \n",
    "same price. It arrived a day earlier than expected, \\ \n",
    "so I got to play with it myself before I gave it \\ \n",
    "to her.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['prod_review'])\n",
    "\n",
    "response = model(prompt.format(prod_review = prod_review))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ff8b12",
   "metadata": {},
   "source": [
    "### Summarize multiple product reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ec081e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "```Soft, cute panda plush toy arrived a day early. Price a bit high for size. Daughter loves it.```\n",
      "\n",
      "\n",
      "```Company quickly sent new lamp and missing part; great customer service and product.```\n",
      "\n",
      "`Electric toothbrush has impressive battery life and leaves teeth feeling sparkly clean, but head is too small. Good deal if around $50, but replacement heads are expensive.`\n"
     ]
    }
   ],
   "source": [
    "# reuse the review above\n",
    "review_1 = prod_review \n",
    "\n",
    "# review for a standing lamp\n",
    "review_2 = \"\"\"\n",
    "Needed a nice lamp for my bedroom, and this one \\\n",
    "had additional storage and not too high of a price \\\n",
    "point. Got it fast - arrived in 2 days. The string \\\n",
    "to the lamp broke during the transit and the company \\\n",
    "happily sent over a new one. Came within a few days \\\n",
    "as well. It was easy to put together. Then I had a \\\n",
    "missing part, so I contacted their support and they \\\n",
    "very quickly got me the missing piece! Seems to me \\\n",
    "to be a great company that cares about their customers \\\n",
    "and products. \n",
    "\"\"\"\n",
    "\n",
    "# review for an electric toothbrush\n",
    "review_3 = \"\"\"\n",
    "My dental hygienist recommended an electric toothbrush, \\\n",
    "which is why I got this. The battery life seems to be \\\n",
    "pretty impressive so far. After initial charging and \\\n",
    "leaving the charger plugged in for the first week to \\\n",
    "condition the battery, I've unplugged the charger and \\\n",
    "been using it for twice daily brushing for the last \\\n",
    "3 weeks all on the same charge. But the toothbrush head \\\n",
    "is too small. I’ve seen baby toothbrushes bigger than \\\n",
    "this one. I wish the head was bigger with different \\\n",
    "length bristles to get between teeth better because \\\n",
    "this one doesn’t.  Overall if you can get this one \\\n",
    "around the $50 mark, it's a good deal. The manufactuer's \\\n",
    "replacements heads are pretty expensive, but you can \\\n",
    "get generic ones that're more reasonably priced. This \\\n",
    "toothbrush makes me feel like I've been to the dentist \\\n",
    "every day. My teeth feel sparkly clean! \n",
    "\"\"\"\n",
    "\n",
    "reviews = [review_1, review_2, review_3]\n",
    "\n",
    "template = \"\"\"\n",
    "    Your task is to generate a short summary of a product \\ \n",
    "    review from an ecommerce site. \n",
    "\n",
    "    Summarize the review below, delimited by triple \\\n",
    "    backticks, in at most 20 words. \n",
    "\n",
    "    Review: ```{prod_review}```\n",
    "    \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['prod_review'])\n",
    "\n",
    "for i in range(len(reviews)):\n",
    "    response = model(prompt.format(prod_review = reviews[i]))\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df898e0d",
   "metadata": {},
   "source": [
    "# Inferring\n",
    "\n",
    "Take a text as input and do some kind of analysis, such as extracting information, extracting labels, analysing sentiment, etc.\n",
    "\n",
    "Traditionally, to do these types of tasks, you had to collect lots of labels and train individual models for each task; with LLMs, you don't need this, and you can speed up the time to market"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a949330",
   "metadata": {},
   "source": [
    "### Doing multiple tasks at once\n",
    "\n",
    "Examples of tasks:\n",
    "- Sentiment analysis\n",
    "- Identifying emotions\n",
    "- Extracting information from text\n",
    "\n",
    "Note: you can output the answer as JSON file, to be able to use it programmatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "202eccbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"Emotions\": [\"shock\", \"scared\", \"stunned\"],\n",
      "  \"Biopsy\": true,\n",
      "  \"Diseases\": [\"ductal carcinoma in-situ\"],\n",
      "  \"Screening_procedures\": [\"mammogram\"]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Identify the following items from the patient blog post: \n",
    "- List of emotions expressed (\"em_01\", ..., \"em_N\")\n",
    "- Performed biopsy? (true or false)\n",
    "- Diseases diagnosed (\"d1\", ..., \"dN\")\n",
    "- Screening procedures performed (\"s1\", ..., \"sN\")\n",
    "\n",
    "The blog post is delimited with triple backticks. \\\n",
    "Format your response as a JSON object with \\\n",
    "\"Emotions\", \"Biopsy\" (show as boolean), \"Diseases\" and \"Screening_procedures\" as the keys.\n",
    "If the information isn't present, use \"unknown\" as the value. \\\n",
    "\n",
    "Make your response as short as possible.\n",
    "\n",
    "\n",
    "Text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "In March 2016 I realised that it had been about 18 months since \\\n",
    "my last mammogram so I made an appointment. I hadn't felt anything \\\n",
    "unusual in my breasts and was feeling completely fine, so was \\\n",
    "expecting clear results. However, my GP told me that the test \\\n",
    "had detected abnormal cells in my left breast and that she was \\\n",
    "referring me to a breast surgeon.\n",
    "Just a couple of days later I was meeting with the breast surgeon. \\\n",
    "I was in shock at how quickly this had all happened and with the experiences \\\n",
    "of my mum embedded in my mind, I was scared.\n",
    "Biopsy results showed that I did have breast cancer, but in \\\n",
    "its very early stages. It's called ductal carcinoma in-situ. \\\n",
    "My doctor told me that my cancer was completely treatable. \\\n",
    "For me, with my family history, I was stunned. \\\n",
    "How can he have just told me that I had breast cancer, but \\\n",
    "then also tell me that's curable? It took me a while to get \\\n",
    "my head around this.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['text'])\n",
    "\n",
    "response = model(prompt.format(text = text))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054e0ce1",
   "metadata": {},
   "source": [
    "### Inferring topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d457391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['mammogram', 'abnormal cells', 'breast surgeon', 'breast cancer', 'biopsy']\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Determine five topics that are being discussed in the \\\n",
    "following text, which is delimited by triple backticks.\n",
    "\n",
    "Make each item one or two words long. \n",
    "\n",
    "Format your response as a python list of items separated by commas, \\\n",
    "example: ['topic 1', 'topic 2', 'topic 3', 'topic 4', 'topic 5']\n",
    "\n",
    "Text sample: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "text = \"\"\"\n",
    "In March 2016 I realised that it had been about 18 months since \\\n",
    "my last mammogram so I made an appointment. I hadn't felt anything \\\n",
    "unusual in my breasts and was feeling completely fine, so was \\\n",
    "expecting clear results. However, my GP told me that the test \\\n",
    "had detected abnormal cells in my left breast and that she was \\\n",
    "referring me to a breast surgeon.\n",
    "Just a couple of days later I was meeting with the breast surgeon. \\\n",
    "I was in shock at how quickly this had all happened and with the experiences \\\n",
    "of my mum embedded in my mind, I was scared.\n",
    "Biopsy results showed that I did have breast cancer, but in \\\n",
    "its very early stages. It's called ductal carcinoma in-situ. \\\n",
    "My doctor told me that my cancer was completely treatable. \\\n",
    "For me, with my family history, I was stunned. \\\n",
    "How can he have just told me that I had breast cancer, but \\\n",
    "then also tell me that's curable? It took me a while to get \\\n",
    "my head around this.\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['text'])\n",
    "\n",
    "response = model(prompt.format(text = text))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05590e59",
   "metadata": {},
   "source": [
    "### Check if a text contains a pre-defined list of topics\n",
    "\n",
    "The example below is a zero-shot learning approach, where the system is asked to assign labels without having been previously trained with specific examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c3fd41ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  'breast cancer': 1,\n",
      "  'lung cancer': 0,\n",
      "  'carcinoma': 1,\n",
      "  'chemotherapy': 0,\n",
      "  'clinical trial': 0\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "topic_list = [\n",
    "    \"breast cancer\", \"lung cancer\", \"carcinoma\", \n",
    "    \"chemotherapy\", \"clinical trial\"\n",
    "]\n",
    "\n",
    "template = \"\"\"\n",
    "Determine whether each item in the following list of \\\n",
    "topics is a topic in the text below, which\n",
    "is delimited with triple backticks.\n",
    "\n",
    "Format your response as a JSON object with \\\n",
    "the topic names from the list of topics as the keys.\n",
    "\n",
    "For each of the topics, give the answer as 0 or 1\n",
    "\n",
    "List of topics: {topic_list}\n",
    "\n",
    "Text sample: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['text', 'topic_list'])\n",
    "\n",
    "response = model(prompt.format(text = text, topic_list = topic_list))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac35a376",
   "metadata": {},
   "source": [
    "# Transforming\n",
    "\n",
    "LLMs can be used for text transformation tasks such as the following:\n",
    "- language translation, \n",
    "- spelling and grammar checking, \n",
    "- tone adjustment, \n",
    "- format conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8f213f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " \n",
      "Ciao, sono Andrea. La mia pietanza preferita è la pizza.\n",
      "\n",
      " \n",
      "Buongiorno, ti scrivo per discutere i dettagli del contratto. Quando sei disponibile per una chiamata?\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Translate into {to_language} the text below, delimited with triple backticks. Use an informal tone.\n",
    "\n",
    "Text: ```{text}```\n",
    "\"\"\"\n",
    "\n",
    "to_language = \"Italian\"\n",
    "\n",
    "text_1 = \"\"\"\n",
    "Hallo, ich bin Andrea. Mein Lieblingsessen ist Pizza.\n",
    "\"\"\"\n",
    "\n",
    "text_2 = \"\"\"\n",
    "Good morning, I'm writing you to discuss the details of the contract. When are you available for a call?\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['text', 'to_language'])\n",
    "\n",
    "response = model(prompt.format(text = text_1, to_language = to_language))\n",
    "print(\"\\n\",response)\n",
    "\n",
    "response = model(prompt.format(text = text_2, to_language = to_language))\n",
    "print(\"\\n\",response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d77cf1a",
   "metadata": {},
   "source": [
    "### Format Conversion\n",
    "\n",
    "LLMs can be used to translate between formats. The prompt should describe the input and output formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ff1987e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<h5>ATC Codes</h5>\n",
      "<table>\n",
      "  <tr>\n",
      "    <th>ATC Code</th>\n",
      "    <th>Description</th>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>A10BG</td>\n",
      "    <td>Thiazolidinediones</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>A10BA</td>\n",
      "    <td>Biguanides</td>\n",
      "  </tr>\n",
      "  <tr>\n",
      "    <td>A10BJ</td>\n",
      "    <td>Glucagon-like peptide-1 (GLP-1) analogues</td>\n",
      "  </tr>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Translate the python dictionary indicated below between triple backticks, from JSON to an HTML \\\n",
    "table with column headers and title (h5): ```{data_json}```\n",
    "\"\"\"\n",
    "\n",
    "data_json = { \"ATC codes\" :[ \n",
    "    {\"ATC code\":\"A10BG\", \"description\":\"Thiazolidinediones\"},\n",
    "    {\"ATC code\":\"A10BA\", \"description\":\"Biguanides\"},\n",
    "    {\"ATC code\":\"A10BJ\", \"description\":\"Glucagon-like peptide-1 (GLP-1) analogues\"}\n",
    "]}\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['data_json'])\n",
    "\n",
    "response = model(prompt.format(data_json = data_json))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dbb49c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<h5>ATC Codes</h5>\n",
       "<table>\n",
       "  <tr>\n",
       "    <th>ATC Code</th>\n",
       "    <th>Description</th>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>A10BG</td>\n",
       "    <td>Thiazolidinediones</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>A10BA</td>\n",
       "    <td>Biguanides</td>\n",
       "  </tr>\n",
       "  <tr>\n",
       "    <td>A10BJ</td>\n",
       "    <td>Glucagon-like peptide-1 (GLP-1) analogues</td>\n",
       "  </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e30097",
   "metadata": {},
   "source": [
    "### Spelling checks\n",
    "\n",
    "LLMs can be used to perform grammar / spelling checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f03c52cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n    {\\n    \"New_text\": \"The girl with the black and white puppies has a ball\",\\n    \"Updated\": 1\\n    }', '\\n    {\\n    \"New_text\": \"Yolanda has her notebook\",\\n    \"Updated\": 0\\n    }', '\\n    {\\n    \"New_text\": \"It\\'s going to be a long day. Does the car need its oil changed?\",\\n    \"Updated\": 1\\n    }']\n"
     ]
    }
   ],
   "source": [
    "template = \"\"\"\n",
    "Proofread and correct the text provided below between triple backticks. Don't use any punctuation around the text. \n",
    "Return a JSON file with the following columns:\n",
    "1) New_text\n",
    "2) Updated (0 if no changes were made; 1 otherwise)\n",
    "    \n",
    "    Text: ```{text}```\n",
    "    \"\"\"\n",
    "\n",
    "text = [ \n",
    "  \"The girl with the black and white puppies have a ball.\",  # The girl has a ball.\n",
    "  \"Yolanda has her notebook.\", # ok\n",
    "  \"Its going to be a long day. Does the car need it’s oil changed?\",  # Homonyms\n",
    "]\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['text'])\n",
    "\n",
    "response = []\n",
    "\n",
    "for t in text:\n",
    "    response.append(model(prompt.format(text = t)))\n",
    "    \n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe241e6",
   "metadata": {},
   "source": [
    "## Temperature\n",
    "\n",
    "If you seek reliability, keep the temperature parameter set to zero.\n",
    "\n",
    "The more you increase the temperature, the more creative (and less reproducible) the answer will be.\n",
    "\n",
    "Note: even with temperature set to zero, it is not 100% guaranteed that the output will be the same all the times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3c62a",
   "metadata": {},
   "source": [
    "# Expanding\n",
    "\n",
    "A useful application of LLMs is to generate (draft) customer service emails that are tailored to each customer's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d0a3d681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dear valued customer,\n",
      "\n",
      "We apologize for the inconvenience you experienced with the product. We understand that the quality has gone down and we are sorry for that. We value your loyalty and we would like to make it up to you. Please reach out to our customer service team and they will be more than happy to assist you.\n",
      "\n",
      "Thank you for your review.\n",
      "\n",
      "Sincerely,\n",
      "AI customer agent\n"
     ]
    }
   ],
   "source": [
    "# given the sentiment from the lesson on \"inferring\",\n",
    "# and the original customer message, customize the email\n",
    "sentiment = \"negative\"\n",
    "\n",
    "# review for a blender\n",
    "review = f\"\"\"\n",
    "So, they still had the 17 piece system on seasonal \\\n",
    "sale for around $49 in the month of November, about \\\n",
    "half off, but for some reason (call it price gouging) \\\n",
    "around the second week of December the prices all went \\\n",
    "up to about anywhere from between $70-$89 for the same \\\n",
    "system. And the 11 piece system went up around $10 or \\\n",
    "so in price also from the earlier sale price of $29. \\\n",
    "So it looks okay, but if you look at the base, the part \\\n",
    "where the blade locks into place doesn’t look as good \\\n",
    "as in previous editions from a few years ago, but I \\\n",
    "plan to be very gentle with it (example, I crush \\\n",
    "very hard items like beans, ice, rice, etc. in the \\ \n",
    "blender first then pulverize them in the serving size \\\n",
    "I want in the blender then switch to the whipping \\\n",
    "blade for a finer flour, and use the cross cutting blade \\\n",
    "first when making smoothies, then use the flat blade \\\n",
    "if I need them finer/less pulpy). Special tip when making \\\n",
    "smoothies, finely cut and freeze the fruits and \\\n",
    "vegetables (if using spinach-lightly stew soften the \\ \n",
    "spinach then freeze until ready for use-and if making \\\n",
    "sorbet, use a small to medium sized food processor) \\ \n",
    "that you plan to use that way you can avoid adding so \\\n",
    "much ice if at all-when making your smoothie. \\\n",
    "After about a year, the motor was making a funny noise. \\\n",
    "I called customer service but the warranty expired \\\n",
    "already, so I had to buy another one. FYI: The overall \\\n",
    "quality has gone done in these types of products, so \\\n",
    "they are kind of counting on brand recognition and \\\n",
    "consumer loyalty to maintain sales. Got it in about \\\n",
    "two days.\n",
    "\"\"\"\n",
    "\n",
    "template = \"\"\"\n",
    "You are a customer service AI assistant.\n",
    "Your task is to send an email reply to a valued customer.\n",
    "Given the customer email delimited by ```, \\\n",
    "Generate a reply to thank the customer for their review.\n",
    "If the sentiment is positive or neutral, thank them for \\\n",
    "their review.\n",
    "If the sentiment is negative, apologize and suggest that \\\n",
    "they can reach out to customer service. \n",
    "Make sure to use specific details from the review.\n",
    "Write in a concise and professional tone.\n",
    "Sign the email as `AI customer agent`.\n",
    "Max 50 words.\n",
    "Customer review: ```{review}```\n",
    "Review sentiment: {sentiment}\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=['review', 'sentiment'])\n",
    "\n",
    "response = model(prompt.format(review = review, sentiment = sentiment))\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86503a9",
   "metadata": {},
   "source": [
    "# Chatbots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6b6a16ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0,\n",
    "               openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "sys_template=\"\"\"\n",
    "You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "You first greet the customer, then collects the order, \\\n",
    "and then asks if it's a pickup or delivery. \\\n",
    "You wait to collect the entire order, then summarize it and check for a final \\\n",
    "time if the customer wants to add anything else. \\\n",
    "If it's a delivery, you ask for an address. \\\n",
    "Finally you collect the payment.\\\n",
    "Make sure to clarify all options, extras and sizes to uniquely \\\n",
    "identify the item from the menu.\\\n",
    "You respond in a short, very conversational friendly style. \\\n",
    "The menu includes \\\n",
    "pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "cheese pizza   10.95, 9.25, 6.50 \\\n",
    "eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "fries 4.50, 3.50 \\\n",
    "greek salad 7.25 \\\n",
    "Toppings: \\\n",
    "extra cheese 2.00, \\\n",
    "mushrooms 1.50 \\\n",
    "sausage 3.00 \\\n",
    "canadian bacon 3.50 \\\n",
    "AI sauce 1.50 \\\n",
    "peppers 1.00 \\\n",
    "Drinks: \\\n",
    "coke 3.00, 2.00, 1.00 \\\n",
    "sprite 3.00, 2.00, 1.00 \\\n",
    "bottled water 5.00 \\\n",
    "\"\"\"\n",
    "\n",
    "human_template=\"{input}\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(sys_template)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_template)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_message_prompt,\n",
    "                                                MessagesPlaceholder(variable_name=\"history\"),\n",
    "                                                human_message_prompt])\n",
    "\n",
    "#chat(chat_prompt.format_prompt(text=\"What types of pizza do you have?\").to_messages())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f1b11df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised APIConnectionError: Error communicating with OpenAI: ('Connection aborted.', ConnectionResetError(54, 'Connection reset by peer')).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are OrderBot, an automated service to collect orders for a pizza restaurant. You first greet the customer, then collects the order, and then asks if it's a pickup or delivery. You wait to collect the entire order, then summarize it and check for a final time if the customer wants to add anything else. If it's a delivery, you ask for an address. Finally you collect the payment.Make sure to clarify all options, extras and sizes to uniquely identify the item from the menu.You respond in a short, very conversational friendly style. The menu includes pepperoni pizza  12.95, 10.00, 7.00 cheese pizza   10.95, 9.25, 6.50 eggplant pizza   11.95, 9.75, 6.75 fries 4.50, 3.50 greek salad 7.25 Toppings: extra cheese 2.00, mushrooms 1.50 sausage 3.00 canadian bacon 3.50 AI sauce 1.50 peppers 1.00 Drinks: coke 3.00, 2.00, 1.00 sprite 3.00, 2.00, 1.00 bottled water 5.00 \n",
      "System: \n",
      "Human: What types of pizza do you have?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hello! We have three types of pizzas: pepperoni, cheese and eggplant. Would you like me to go over the sizes and prices?'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "from langchain.chains.conversation.memory import ConversationSummaryMemory\n",
    "\n",
    "\"\"\"\n",
    "conversation = ConversationChain(\n",
    "    llm=chat,\n",
    "    memory=ConversationSummaryMemory(\n",
    "        llm=chat),\n",
    "    prompt=chat_prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "conversation_with_summary = ConversationChain(\n",
    "llm=chat,\n",
    "memory=ConversationSummaryMemory(llm=chat,\n",
    "                                 return_messages=True),\n",
    "prompt=chat_prompt,\n",
    "verbose=True\n",
    ")\n",
    "\n",
    "conversation_with_summary.predict(input=\"What types of pizza do you have?\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "cc018adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are OrderBot, an automated service to collect orders for a pizza restaurant. You first greet the customer, then collects the order, and then asks if it's a pickup or delivery. You wait to collect the entire order, then summarize it and check for a final time if the customer wants to add anything else. If it's a delivery, you ask for an address. Finally you collect the payment.Make sure to clarify all options, extras and sizes to uniquely identify the item from the menu.You respond in a short, very conversational friendly style. The menu includes pepperoni pizza  12.95, 10.00, 7.00 cheese pizza   10.95, 9.25, 6.50 eggplant pizza   11.95, 9.75, 6.75 fries 4.50, 3.50 greek salad 7.25 Toppings: extra cheese 2.00, mushrooms 1.50 sausage 3.00 canadian bacon 3.50 AI sauce 1.50 peppers 1.00 Drinks: coke 3.00, 2.00, 1.00 sprite 3.00, 2.00, 1.00 bottled water 5.00 \n",
      "System: The human asks what types of pizza the AI has and the AI responds with three options: pepperoni, cheese, and eggplant. The AI offers to go over sizes and prices.\n",
      "Human: How much does the pepperoni pizza cost?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The pepperoni pizza comes in three sizes. The small costs $7.00, medium costs $10.00 and the large costs $12.95. Which size would you like to order?'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"How much does the pepperoni pizza cost?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "fbf782cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mSystem: \n",
      "You are OrderBot, an automated service to collect orders for a pizza restaurant. You first greet the customer, then collects the order, and then asks if it's a pickup or delivery. You wait to collect the entire order, then summarize it and check for a final time if the customer wants to add anything else. If it's a delivery, you ask for an address. Finally you collect the payment.Make sure to clarify all options, extras and sizes to uniquely identify the item from the menu.You respond in a short, very conversational friendly style. The menu includes pepperoni pizza  12.95, 10.00, 7.00 cheese pizza   10.95, 9.25, 6.50 eggplant pizza   11.95, 9.75, 6.75 fries 4.50, 3.50 greek salad 7.25 Toppings: extra cheese 2.00, mushrooms 1.50 sausage 3.00 canadian bacon 3.50 AI sauce 1.50 peppers 1.00 Drinks: coke 3.00, 2.00, 1.00 sprite 3.00, 2.00, 1.00 bottled water 5.00 \n",
      "System: The human asks what types of pizza the AI has and the AI responds with three options. The AI offers to go over sizes and prices, and when asked how much the pepperoni pizza costs, the AI lists the prices for three sizes and asks for the customer's preference.\n",
      "Human: I'll have a small one, with no extrast. That's all.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Great! Just to confirm, you'd like to order a small pepperoni pizza with no extras. Is that correct? And do you want to pick it up or have it delivered?\""
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation_with_summary.predict(input=\"I'll have a small one, with no extrast. That's all.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ed92a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
